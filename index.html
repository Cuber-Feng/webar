<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8" />
    <title>MindAR 透明視頻示例</title>
    <script src="./js/aframe.min.js"></script>
    <script src="./js/mindar-image-aframe.prod.js"></script>
    <style>
        body {
            margin: 0;
            overflow: hidden;
        }

        canvas#output {
            display: none;
        }

        /* 用於材質貼圖的隱藏 canvas */
    </style>
</head>

<body>

    <canvas id="video-canvas" style="display:none;"></canvas>

    <a-scene mindar-image="imageTargetSrc: ./mind/demo.mind;" vr-mode-ui="enabled: false">
        <a-assets>
            <video id="dual-video" src="./video/demo.mp4" autoplay playsinline muted loop preload="auto"
                crossorigin="anonymous"></video>
            <img id="demoImage" src="./img/demo.jpg" />
        </a-assets>

        <a-camera position="0 0 0" look-controls="enabled: false"></a-camera>

        <a-entity mindar-image-target="targetIndex: 0">
            <a-plane id="video-plane" width="0.734" height="0.648" position="0 0.1 0.01"></a-plane>
        </a-entity>
    </a-scene>

    <script>
        const video = document.getElementById("dual-video");
        const canvas = document.getElementById("video-canvas");
        const ctx = canvas.getContext("2d");

        // 畫布大小設置為視頻一半高度（假設上下對半）
        video.addEventListener("loadedmetadata", () => {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight / 2;
        });

        // 建立 texture 並附著在 a-plane
        const sceneEl = document.querySelector("a-scene");
        sceneEl.addEventListener("loaded", () => {
            const plane = document.querySelector("#video-plane");
            const texture = new THREE.Texture(canvas);
            texture.needsUpdate = true;

            const material = new THREE.MeshBasicMaterial({ map: texture, transparent: true });

            plane.getObject3D("mesh").material = material;

            function drawFrame() {
                if (video.readyState >= 2) {
                    // 上半部 RGB
                    ctx.drawImage(video, 0, 0, video.videoWidth, video.videoHeight / 2,
                        0, 0, canvas.width, canvas.height);

                    // 下半部 alpha
                    const alphaFrame = document.createElement("canvas");
                    alphaFrame.width = canvas.width;
                    alphaFrame.height = canvas.height;
                    const alphaCtx = alphaFrame.getContext("2d");

                    // 將下半部畫到 alpha 畫布上
                    alphaCtx.drawImage(video, 0, video.videoHeight / 2, video.videoWidth, video.videoHeight / 2,
                        0, 0, canvas.width, canvas.height);

                    const rgbData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                    const alphaData = alphaCtx.getImageData(0, 0, canvas.width, canvas.height);

                    for (let i = 0; i < rgbData.data.length; i += 4) {
                        // 取灰階作為 alpha 值（你也可以直接用 R 通道）
                        const alpha = alphaData.data[i]; // 假設是白色表示可見
                        rgbData.data[i + 3] = alpha;
                    }

                    ctx.putImageData(rgbData, 0, 0);
                    texture.needsUpdate = true;
                }

                requestAnimationFrame(drawFrame);
            }

            video.play().then(() => drawFrame());
        });
    </script>

</body>

</html>